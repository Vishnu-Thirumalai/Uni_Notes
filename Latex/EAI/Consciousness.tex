\section{Consciousness}
\emph{Consciousness} is the mind referred to in 'I think therefore I am'. It's the only fully known constant that is common to all humans, but we have no idea what it is. 

\subsection{Difficulties in Explaining Consciousness}
\begin{enumerate}
    \item The 'easy' - how the brain works, responds to inputs, adjusts with behaviour - difficult, but related to intelligence and aren't subjective
    \item The 'hard' - how does physical matter give rise to subjective experiences. Taking in information, processing and outputting is common to humans and machines - but 'experiencing' something is separate, where does that come from and is it optional? 
\end{enumerate}


\subsection{Definition}
Consciousness is a 'subjective experience' (Max Tegmark, Life 3.0), what's it's like to 'be' something. Something is said to be conscious if there is a subjective way the world appears to be from its point of view - it has its own experiences and feelings (Thomas Nagel, The Philosophical Review). 

\subsection{Understanding continued}
Understanding results from a conscious awareness about the relationship between syntax and semantics. However, modern NLP systems use context to 'understand' a word by how it's used, rather than the actual meaning - it behaves like it understands, but doesn't have an \emph{intention} behind the words, it just says them because they're the correct response.

\subsubsection{Functionalism}
If a system fills the same functional role as another system, it is that system (i.e. duck typing - if it talks/walks/quacks like a duck, it is a duck). The chinese room experiment argues against functionalism (specifically the computational theory of the mind, which says the mind is an information processing system), saying that the system behaving as if it is conscious doesn't mean that it is. 

\subsection{Theories of Consciousness}
\subsubsection{Dualist Theories}
\begin{enumerate}
    \item Substance Dualism - a separation between the consciousness and the physical world. i.e. 'I think therefore I am'
    \item Property Dualism - physical and conscious properties of objects are distinct 
\end{enumerate}

\subsubsection{Physicalist Theories}
Consciousness (and everything else) can be explained by physical properties (e.g. functionalism where doing is being, or theories that particular arrangements of molecules give rise to consciousness) 

\subsubsection{Philosophical Zombies}
A \emph{philosophical zombie} is an exact physical duplicate of a person that acts the same way, but doesn't have experiences or consciousness. Such a being is concievable, and \emph{logically} (maybe not nomically) possible. Since it's physically the same and not conscious, property dualism must hold and physicalism is false. \\

However, the definition of the zombie is slowly becoming less believable, as we learn more about how the brain works. The definition itself assumes that a physical duplicate isn't conscious, which implies property dualism in the statement.\\

Even ignoring these flaws, this experiment still doesn't explain the gap between physical matter and subjective experiences.

\subsection{Conscious State}
\begin{enumerate}
    \item A state where one is aware that one is in that state. e.g. desiring something, and knowing you desire that thing
    \item A state where you experience \emph{qualia} (qualitative feelings/properties/ sensory feels like touch/taste). e.g. being 'moved' by a sunset, feeling love
    \item A state that knows it relates to/is distinct from/interacts with other states (\emph{access consciousness}). e.g. visual states can be used by other parts of the brain
\end{enumerate}


\subsection{Problems with Consciousness}

\subsubsection{What is it?}
It's impossible to directly describe consciousness/qualia - inverted qualia thought experiments discuss how people don't experience things in the same way. e.g. colour blindness, the blue/gold dress (even with the same base, people had different responses). People have different behavioural reactions to the same thing - people find it difficult to describe qualia (e.g. the taste of an apple), making it hard to confirm that we all experience the world in the same way. 

\subsubsection{How does it exist?}
High level properties of a system can usually be explained by a combination of low-level properties. e.g the molecular structure of water explains why its a liquid. However, this isn't the case for consciousness (the 'hard' problem) - we can't explain consciousness with physical brain signals.\\

It's possible that we're \emph{cognitively closed} to consciousness - our intelligence/cognitive ability \emph{can't} understand it, like how animals can't understand democracy.\\

Some people argue that being unable to explain how it arises from physical properties means that it doesn't - and this in turn means we can't build a conscious AI system.

\subsubsection{Why Does it exist?}
From an evolutionary point of view, consciousness might not be required - the most basic function of the brain (to keep a human alive) is done without conscious thought. It's argued that more complex feelings (disgust/shame/lust) evolved for social reasons, as shortcuts to more complex underlying processes. \\

There's also the question if it affects our behaviour - the way we act is a completely physical process, but consciousness currently can't be explained by physical methods - so how can something not physical affect the physical? Other theories state that consciousness is \emph{epiphenomenal} - it's a byproduct, like steam from a train and is simply used to express behaviour to ourselves(self awareness) rather than influencing it.

\subsection{Roles of Consciousness}
Assuming that it does have a role and isn't epiphenomenal, it provides the following benefits:
\begin{enumerate}
    \item Gives us self-awareness/meta-awareness - this allows more flexible approaches to dealing with new situations than unconscious reaction\\ \quad - having beliefs/desires and knowing that others do (\emph{empathy}) allows for better social co-ordination
    \item Presents a unified representation of reality, rather than individual sensor inputs - again, this gives more flexible responses than individual reactions. 
    \item It allows the entire brain to focus on a particular piece of information, and allows all mental subsystems to have access to the data whereas if it was in the background it might have been ignored. e.g. focusing on a stop sign
\end{enumerate}

\subsection{Information Theoretic Theories (Access Consciousness)}
Theories that posit that consciousness is for the storage/processing/availability of information.

\subsubsection{Global Workspace Theory}
Consciousness is a competition between processors/data - the most important information is broadcast and becomes part of the \emph{global workspace} for the brain to focus on. Recurrent feedback from the existing workspace and other inputs strengthen it. The availability and recurrent strengthening make the information conscious, in that it's globally available.

\subsubsection{Integrated Information Theory (IIT)}
Consciousness is measured on how well information is integrated together and available (\emph{access consciousness}) to other subsystems (sense, behaviour, coordination \dots). \\
This integration is represented as the mathematical constant $\Phi$ - the higher phi, the more consciousness the organism/object has. This implies \emph{panpsychism}, a dualist theory that says that everything has some level of (proto-)consciousness.\\
Since IIT uses a measure of $\Phi$, the structure of the system is important as well, not just how it acts (i.e. rejects functionalism, the chinese room doesn't match the below criteria). However, it doesn't give any restrictions on what can achieve $\Phi$, and is thus substrate independent.

\subsubsection{Criteria for IIT}
\begin{enumerate}
    \item Has information about it self - books/etc. contain information about other things (so need external knowledge of symbols/etc.), with highly conscious systems one can learn about the previous/next state only from the system
    \item Integration of information: how much the information depends on other parts of the system (i.e. if you cut it in half, how much information is lost?)
    \begin{itemize}
        \item If you cut a book in half, you can just read both parts - it's just the sum of the information of the parts
        \item The brain/RNN has lots of recurrent connections/feedback layers, so information is calculated by the flow between them
    \end{itemize}
    \item Maximality of Integration - the system must have more integrated information than the sum of its parts, and more than any system it's part of (e.g. humans in the world) 
\end{enumerate}
These criteria support IIT as a theory for consciousness: a conscious system needs self-awareness, structure and self-integration, lots of available information and a hard border on what is/isn't conscious ($\Phi$).

\subsection{Consciousness for AI}
AGI/Superintelligence don't mention consciousness - it's also not a part of the definition of intelligence. This doesn't mean it's not needed, or that artificial consciousness isn't possible, simply that the definitions don't commit to them.\\

If an AI had consciousness, this would imply they had experiences/emotions/pain - they would be another species like, but not the same as humans. This would completely redefine humans' relationship with the rest of the world and would change how we treated AI/machines.\\

There's a debate if machines even need consciousness - humans may have evolved it to be able to internalise feelings and perform interoception, but machines can just take internal readings on anything they need.

\subsubsection{Recognising Consciousness}
We might be able to recognise by functionalism (it acts like it is), a high value of $\Phi$, or some other measure to judge that it has the right architecture. We'd never be able to fully confirm it though, as we're unable to confirm that animals are conscious. 